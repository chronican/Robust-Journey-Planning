{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.app.name': 'Hteam_final'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>7201</td><td>application_1618324153128_6930</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_6930/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_6930_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>7218</td><td>application_1618324153128_6949</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_6949/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster077.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_6949_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>7221</td><td>application_1618324153128_6952</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_6952/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster070.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_6952_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>7223</td><td>application_1618324153128_6954</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_6954/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster069.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_6954_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr><tr><td>7227</td><td>application_1618324153128_6958</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_6958/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster077.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_6958_01_000001/ebouille\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"Hteam_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project for Team H - Robust Journey Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>7228</td><td>application_1618324153128_6959</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster040.iccluster.epfl.ch:8088/proxy/application_1618324153128_6959/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster067.iccluster.epfl.ch:8042/node/containerlogs/container_e01_1618324153128_6959_01_000001/ebouille\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fcc1e272410>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dwu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "import os\n",
    "username = os.environ['JUPYTERHUB_USER']\n",
    "\n",
    "username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#put the user name to be the same as above\n",
    "username = 'dwu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fcc1e272410>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import copy\n",
    "from hdfs3 import HDFileSystem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import folium\n",
    "\n",
    "username = 'dwu'\n",
    "hdfs = HDFileSystem(host='hdfs://iccluster040.iccluster.epfl.ch', port=8020, user='ebouille') # impersonate ebouille to read the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the timetable files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_times = spark.read.csv(\"/data/sbb/csv/timetable/stop_times/2019/05/07/stop_times.csv\", header=True)\n",
    "#stop_times.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips = spark.read.csv(\"/data/sbb/csv/timetable/trips/2019/05/07/trips.csv\", header=True)\n",
    "#trips.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "routes = spark.read.csv(\"/data/sbb/csv/timetable/routes/2019/05/07/routes.csv\", header=True)\n",
    "#routes.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calendar = spark.read.csv(\"/data/sbb/csv/timetable/calendar/2019/05/07/calendar.csv\", header=True)\n",
    "#calendar.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39027"
     ]
    }
   ],
   "source": [
    "stops = spark.read.orc(\"/data/sbb/orc/geostops/\")\n",
    "#stops.show(3)\n",
    "stops.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Only consider stops within `ZurichHB` in 15 km "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way of compute distance from lat and lon is from : https://stackoverflow.com/questions/27928/calculate-distance-between-two-latitude-longitude-points-haversine-formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import cos, asin, sqrt, pi, ceil, floor\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = pi/180\n",
    "    a = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p) * cos(lat2*p) * (1-cos((lon2-lon1)*p))/2\n",
    "    return 12742 * asin(sqrt(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+----------------+-------------+--------------+\n",
      "|stop_id|           stop_name|        stop_lat|        stop_lon|location_type|parent_station|\n",
      "+-------+--------------------+----------------+----------------+-------------+--------------+\n",
      "|8557033|Oberhasli, Industrie|47.4592670391304|8.49001368400678|         null|              |\n",
      "|8573711|   Zürich, Sädlenweg|47.3677549978138|8.48748043490521|         null|              |\n",
      "|8591828|    Ebmatingen, Dorf|47.3513920447801|8.64100251698261|         null|              |\n",
      "+-------+--------------------+----------------+----------------+-------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "1950"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType, IntegerType, BooleanType, LongType\n",
    "\n",
    "\n",
    "lat_zur = 47.378177\n",
    "lon_zur = 8.540192\n",
    "\n",
    "\n",
    "@F.udf(returnType=BooleanType())\n",
    "def dis_filter(lat, lon):\n",
    "    dis = distance(lat,lon,lat_zur,lon_zur)\n",
    "    return dis < 15\n",
    "\n",
    "#udf_func = F.udf(dis_filter, returnType=BooleanType())\n",
    "\n",
    "stops_filt = stops.filter(dis_filter(stops.stop_lat, stops.stop_lon))\n",
    "stops_filt.show(3)\n",
    "stops_filt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the `stop_ids` to local so that we could use it for route planning algorithm later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stops_ids = stops_filt.select(['stop_id'])\n",
    "stops_filt\n",
    "stops_ids.write.mode(\"overwrite\").parquet('/user/{0}/file/stops_ids/'.format(username))\n",
    "stops_filt.write.mode(\"overwrite\").parquet('/user/{0}/file/stops_filt/'.format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Only consider route in business day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only consider `service` that are avaliable in all business days, that is avaliable from Monday to Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "calendar_filt = calendar.filter( \n",
    "    (calendar.monday == True) & \n",
    "    (calendar.tuesday == True) &\n",
    "    (calendar.wednesday == True) & \n",
    "    (calendar.thursday == True)& \n",
    "    (calendar.friday == True)&\n",
    "    (calendar.saturday == False)&\n",
    "    (calendar.sunday == False) )\n",
    "# calendar_filt.show(3)\n",
    "# calendar_filt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips_filt = trips.join(calendar_filt, 'service_id', 'inner')\\\n",
    ".select('service_id', 'route_id', 'trip_id','direction_id')\n",
    "# trips_filt.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trips_filt = trips_filt.join(routes, 'route_id', 'inner')\\\n",
    ".select(['service_id', 'route_id', 'trip_id','route_desc','route_type','direction_id'])\n",
    "# trips_filt.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 only consider business hour: 7 - 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_times_filt = stop_times.join(trips_filt, 'trip_id', 'inner').drop(*['pickup_type', 'drop_off_type'])\n",
    "#stop_times_filt.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hour = F.udf(lambda x: x.hour, IntegerType())\n",
    "#stop_times_filt = stop_times_filt.withColumn('arrival_time', F.unix_timestamp(stop_times_filt.arrival_time, 'HH:mm:ss'))\n",
    "#stop_times_filt = stop_times_filt.withColumn('departure_time', F.unix_timestamp(stop_times_filt.departure_time, 'HH:mm:ss'))                                            \n",
    "\n",
    "stop_times_filt = stop_times_filt.filter(\n",
    "    (F.hour(stop_times_filt.departure_time) >= 7 )&\n",
    "    (F.hour(stop_times_filt.departure_time) <= 18 )&\n",
    "    (F.hour(stop_times_filt.arrival_time) >= 7 )&\n",
    "    (F.hour(stop_times_filt.arrival_time) <= 18 )\n",
    ")\n",
    "\n",
    "\n",
    "# stop_times_filt.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 build a timetable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a timetable for the route planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[stop_id: string, trip_id: string, arrival_time: string, departure_time: string, stop_sequence: string, service_id: string, route_id: string, route_desc: string, route_type: string, direction_id: string, stop_name: string, stop_lat: double, stop_lon: double, location_type: int, parent_station: string]"
     ]
    }
   ],
   "source": [
    "timetable = stop_times_filt.join(stops_filt,'stop_id','inner')\n",
    "\n",
    "timetable.cache()\n",
    "# timetable.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timetable = timetable.withColumn('arrival_time', F.unix_timestamp(timetable.arrival_time, 'HH:mm:ss'))\n",
    "timetable = timetable.withColumn('departure_time', F.unix_timestamp(timetable.departure_time, 'HH:mm:ss'))\n",
    "# timetable.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timetable =  timetable.withColumn('stop_sequence',timetable.stop_sequence.cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the timetable to local to run the route planning algorithm in local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timetable.write.mode(\"overwrite\").parquet('/user/{0}/file/timetable/'.format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Build walk path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the walk path between each two stops here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+----------------+-------------+--------------+\n",
      "|stop_id|           stop_name|        stop_lat|        stop_lon|location_type|parent_station|\n",
      "+-------+--------------------+----------------+----------------+-------------+--------------+\n",
      "|8557033|Oberhasli, Industrie|47.4592670391304|8.49001368400678|         null|              |\n",
      "|8573711|   Zürich, Sädlenweg|47.3677549978138|8.48748043490521|         null|              |\n",
      "|8591828|    Ebmatingen, Dorf|47.3513920447801|8.64100251698261|         null|              |\n",
      "+-------+--------------------+----------------+----------------+-------------+--------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "stop_ids_lat_lon = {}\n",
    "for row in stops_filt.collect():\n",
    "    stop_ids_lat_lon[row['stop_id']] = (row['stop_lat'],row['stop_lon'])\n",
    "stops_filt.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+----------------+\n",
      "|stop_id|           stop_name|        stop_lat|        stop_lon|\n",
      "+-------+--------------------+----------------+----------------+\n",
      "|8557033|Oberhasli, Industrie|47.4592670391304|8.49001368400678|\n",
      "|8573711|   Zürich, Sädlenweg|47.3677549978138|8.48748043490521|\n",
      "|8591828|    Ebmatingen, Dorf|47.3513920447801|8.64100251698261|\n",
      "+-------+--------------------+----------------+----------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "stops_filt2 = stops_filt.select(['stop_id','stop_name','stop_lat','stop_lon'])\n",
    "stops_filt2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+----------------+\n",
      "|stop_id2|          stop_name2|       stop_lat2|       stop_lon2|\n",
      "+--------+--------------------+----------------+----------------+\n",
      "| 8557033|Oberhasli, Industrie|47.4592670391304|8.49001368400678|\n",
      "| 8573711|   Zürich, Sädlenweg|47.3677549978138|8.48748043490521|\n",
      "| 8591828|    Ebmatingen, Dorf|47.3513920447801|8.64100251698261|\n",
      "+--------+--------------------+----------------+----------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "stops_filt3 = stops_filt.select(['stop_id','stop_name','stop_lat','stop_lon'])\\\n",
    ".withColumnRenamed('stop_id','stop_id2' )\\\n",
    ".withColumnRenamed('stop_name','stop_name2' )\\\n",
    ".withColumnRenamed('stop_lat','stop_lat2' )\\\n",
    ".withColumnRenamed('stop_lon','stop_lon2' )\n",
    "stops_filt3.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The walk path between two stops need to satisfy two conditions:\n",
    "- The distance between two stops need to be in 500m\n",
    "- The minimum walking time is 2 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stops_walk = stops_filt3.crossJoin(stops_filt2)\n",
    "\n",
    "@F.udf(returnType=BooleanType())\n",
    "def dis_filter(lat1, lon1,lat,lon):\n",
    "    dis = distance(lat1,lon1,lat,lon)\n",
    "    return dis < 0.5\n",
    "\n",
    "@F.udf(returnType=LongType())\n",
    "def walk_time_calculator(lat1, lon1,lat,lon):\n",
    "    dis = distance(lat1,lon1,lat,lon)\n",
    "    t = long(((dis*1000)/50)*60)\n",
    "    return t \n",
    "\n",
    "stops_walk = stops_walk\\\n",
    ".filter(\n",
    "    (dis_filter(stops_walk.stop_lat,stops_walk.stop_lon,stops_walk.stop_lat2,stops_walk.stop_lon2))&\n",
    "    (stops_walk.stop_id != stops_walk.stop_id2)\n",
    ")\\\n",
    ".withColumn('walk_time',\\\n",
    "               walk_time_calculator(stops_walk.stop_lat,stops_walk.stop_lon,stops_walk.stop_lat2,stops_walk.stop_lon2))\n",
    "# stops_walk.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stops_walk.write.mode(\"overwrite\").parquet('/user/{0}/file/stops_walk/'.format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#stops_walk.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Predict modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we build our predictive model to analysis the propability distribution of delay time for each stops based on the `istdaten` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter and clean the data to incorperate with the `timetable` data.\n",
    "\n",
    "We clean the data based on the same critieria as the the `timetable` data:\n",
    "- We only consider data in weekdays\n",
    "- We only consider data in business hours (7am - 18pm)\n",
    "- We only consider stops that is in 15 km of `Zurich`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------------+-------------------+--------------+------------+------------------+\n",
      "|stop_id|transport_type|        schedule|             actual|arrival_status|journey_fail|schedule_departure|\n",
      "+-------+--------------+----------------+-------------------+--------------+------------+------------------+\n",
      "|8580472|           Bus|02.02.2020 22:55|02.02.2020 22:57:31|      PROGNOSE|       false|  02.02.2020 22:55|\n",
      "|8580521|           Bus|02.02.2020 22:56|02.02.2020 22:58:19|      PROGNOSE|       false|  02.02.2020 22:56|\n",
      "|8573656|           Bus|02.02.2020 22:56|02.02.2020 22:59:07|      PROGNOSE|       false|  02.02.2020 22:57|\n",
      "+-------+--------------+----------------+-------------------+--------------+------------+------------------+\n",
      "only showing top 3 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "\n",
    "# Load actual data\n",
    "time_table = spark.read.orc(\"/data/sbb/orc/istdaten/\").select(\"bpuic\",\"produkt_id\",\"ankunftszeit\",\"an_prognose\",\n",
    "                                                              \"an_prognose_status\",\"faellt_aus_tf\",\"abfahrtszeit\")\n",
    "# Rename columns for convenience\n",
    "time_table=time_table.withColumnRenamed(\"bpuic\",\"stop_id\")\n",
    "time_table=time_table.withColumnRenamed(\"produkt_id\",\"transport_type\")\n",
    "time_table=time_table.withColumnRenamed(\"ankunftszeit\",\"schedule\")\n",
    "time_table=time_table.withColumnRenamed(\"an_prognose\",\"actual\")\n",
    "time_table=time_table.withColumnRenamed(\"an_prognose_status\",\"arrival_status\")\n",
    "time_table=time_table.withColumnRenamed(\"faellt_aus_tf\",\"journey_fail\")\n",
    "time_table=time_table.withColumnRenamed(\"abfahrtszeit\",\"schedule_departure\")\n",
    "time_table.show(3)\n",
    "# Convert format\n",
    "time_table=time_table.withColumn(\"transport_type\", F.lower(time_table.transport_type))\n",
    "time_table=time_table.withColumn(\"actual\", F.unix_timestamp(time_table.actual, 'dd.MM.yyy HH:mm:ss'))\n",
    "time_table=time_table.withColumn(\"schedule\", F.unix_timestamp(time_table.schedule, 'dd.MM.yyy HH:mm'))\n",
    "time_table=time_table.withColumn(\"schedule_departure\", F.unix_timestamp(time_table.schedule_departure, 'dd.MM.yyy HH:mm'))\n",
    "time_table=time_table.withColumn(\"hour\", F.hour(time_table.schedule.cast(\"timestamp\")))\n",
    "# time_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------+----------+----+\n",
      "|stop_id|transport_type|  schedule|    actual|hour|\n",
      "+-------+--------------+----------+----------+----+\n",
      "|8582005|           bus|1570721160|1570721162|  17|\n",
      "|8580620|           bus|1570721460|1570721505|  17|\n",
      "|8582005|           bus|1570721580|1570721700|  17|\n",
      "|8580617|           bus|1570721640|1570721748|  17|\n",
      "|8580617|           bus|1570686960|1570687003|   7|\n",
      "|8582005|           bus|1570686960|1570687051|   7|\n",
      "|8580620|           bus|1570687260|1570687309|   8|\n",
      "|8582005|           bus|1570687380|1570687417|   8|\n",
      "|8580617|           bus|1570687440|1570687477|   8|\n",
      "|8580617|           bus|1570685160|1570685160|   7|\n",
      "|8582005|           bus|1570685160|1570685208|   7|\n",
      "|8580620|           bus|1570685460|1570685516|   7|\n",
      "|8582005|           bus|1570685580|1570685623|   7|\n",
      "|8580617|           bus|1570685640|1570685659|   7|\n",
      "|8580617|           bus|1570692360|1570692360|   9|\n",
      "|8582005|           bus|1570692360|1570692408|   9|\n",
      "|8580620|           bus|1570692660|1570692684|   9|\n",
      "|8582005|           bus|1570692780|1570692782|   9|\n",
      "|8580617|           bus|1570692840|1570692865|   9|\n",
      "|8580617|           bus|1570699560|1570699560|  11|\n",
      "+-------+--------------+----------+----------+----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "# Filter\n",
    "# only consider actual arrival time\n",
    "time_table=time_table.filter(time_table.arrival_status.isin(['GESCHAETZT', 'PROGNOSE', 'REAL'])).drop(\"arrival_status\")\n",
    "# filter out failed trip\n",
    "time_table=time_table.filter(time_table.journey_fail!=True).drop(\"journey_fail\")\n",
    "# only consider data in 7:00-18:00\n",
    "time_table=time_table.filter((time_table.hour>=7)&(time_table.hour<=18)) \n",
    "time_table=time_table.filter((F.hour(time_table.schedule_departure.cast(\"timestamp\"))>=7)&\n",
    "                             (F.hour(time_table.schedule_departure.cast(\"timestamp\"))<=18))\n",
    "time_table=time_table.filter((F.hour(time_table.schedule_departure.cast(\"timestamp\"))>=7)&\n",
    "                             (F.hour(time_table.schedule_departure.cast(\"timestamp\"))<=18))\n",
    "# only consider data in weekdays\n",
    "time_table=time_table.filter((F.dayofweek(time_table.schedule.cast(\"timestamp\"))>1)&\n",
    "                             (F.dayofweek(time_table.schedule.cast(\"timestamp\"))<7))\n",
    "time_table=time_table.filter((F.dayofweek(time_table.schedule_departure.cast(\"timestamp\"))>1)&\n",
    "                             (F.dayofweek(time_table.schedule_departure.cast(\"timestamp\"))<7))\n",
    "time_table=time_table.drop(\"schedule_departure\")\n",
    "# only consider stops within ZurichHB in 15 km\n",
    "valid_stops = stops_filt.select('stop_id').distinct()\n",
    "time_table=time_table.join(valid_stops, 'stop_id', 'inner')\n",
    "\n",
    "time_table.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 calculate the probability for delays\n",
    "We calculate the success probability for each stop at different hours with the time tolerance for arriving at the next stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model of delay:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We model our delay at each stops as follows:\n",
    "- We model our delay at each stops $s$ as are random variable $X$, which is a function of hour $h$, transport type $t$, that is $X = X(s,h,t)$. The analysis what factors are the delay random variables related tois shown in the `predict_analysis.ipynb`\n",
    "- Given the stop_id $s$, hour $h$, transport type $t$, we need to calculate the  probability that a trip's delay is less than time tolerance $d$, that is :\n",
    "$$Pr(X<d) $$\n",
    "- Given the stop_id $s$, hour $h$, transport type $t$, nn order to estimate the above probability,we assume that the delay different trips are independent, that is the delay for each trips are i.i.d samples $X_1,X_2,..,X_n$ of $X(s,h,t)$. Then we estimate the probability $Pr(X<d) $ as follows:\n",
    "$$Pr(X<d) = \\frac{1}{n} 1\\{X<d\\} = freq(X<d)$$\n",
    "- More percisely, stop_id $s$, hour $h$, transport type $t$, and time tolerance $d$, we calculate the frequence that the delay of the arrival time of the trips is less than the time tolerance, and use the frequence as the probability\n",
    "- By law of large number, we know that $freq(X<d)$ is an unbiased estimator of the probability $Pr(X<d)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate delay distribution\n",
    "delay_table=time_table.withColumn('delay', F.ceil((time_table.actual-time_table.schedule)/60)).drop(\"schedule\", \"actual\")\n",
    "# delay_table.show(3)\n",
    "delay_table=delay_table.groupBy([\"stop_id\",\"transport_type\", \"hour\", \"delay\"]).count().withColumnRenamed(\"count\",\"delay_count\")\n",
    "#delay_table.cache()\n",
    "delay_table.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_table.write.mode(\"overwrite\").parquet('/user/{0}/file/delay_table/'.format(username))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "files = hdfs.glob('/user/{0}/file/delay_table/*.parquet'.format(username))\n",
    "delay_table = pd.DataFrame()\n",
    "for file in files:\n",
    "    with hdfs.open(file) as f:\n",
    "        delay_table = delay_table.append(pd.read_parquet(f))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b3f243893c4ebfa6a3bd0e5f3b0f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='Type:'), Button(description='Table', layout=Layout(width='70px'), st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b311f7c840e249f89c121e936df595fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%local\n",
    "delay_table.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_on_time_prob(stop_id, transport_type, hour, time_tolerance):\n",
    "    \"\"\" Get probabiltiy P(wait_time<=time_tolerance)\n",
    "    Args:\n",
    "        stop_id (int or str):\n",
    "        transport_type (str):\n",
    "        hour (int): hour of a day\n",
    "        time_tolerance (int): delay in minutes\n",
    "    Outputs:\n",
    "        prob (float):\n",
    "    \"\"\"\n",
    "    \n",
    "    delay_dist = np.array(delay_table.filter((delay_table.stop_id==stop_id)&\n",
    "                                             (delay_table.transport_type==transport_type.lower())&\n",
    "                                             (delay_table.hour==hour)).select(\"delay\", \"delay_count\").collect())\n",
    "    if delay_dist.size==0:\n",
    "        return 0\n",
    "    \n",
    "    success=0\n",
    "    for minute, count in delay_dist:\n",
    "        if minute<=time_tolerance:\n",
    "            success+=count\n",
    "    return float(success)/(delay_dist[:,1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local version of get probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def get_on_time_prob(stop_id, transport_type, hour, time_tolerance):\n",
    "    \"\"\" Get probabiltiy P(wait_time<=time_tolerance)\n",
    "    Args:\n",
    "        stop_id (str):\n",
    "        transport_type (str):\n",
    "        hour (int): hour of a day\n",
    "        time_tolerance (int): delay in minutes\n",
    "    Outputs:\n",
    "        prob (float):\n",
    "    \"\"\"\n",
    "    \n",
    "    delay_dist = np.array(delay_table[(delay_table.stop_id==stop_id)&\n",
    "                                             (delay_table.transport_type==transport_type.lower())&\n",
    "                                             (delay_table.hour==hour)][[\"delay\", \"delay_count\"]].values)\n",
    "    if delay_dist.size==0:\n",
    "        return 0\n",
    "    \n",
    "    success=0\n",
    "    for minute, count in delay_dist:\n",
    "        if minute<=time_tolerance:\n",
    "            success+=count\n",
    "    return float(success)/(delay_dist[:,1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978000647039793\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "# one example\n",
    "print(get_on_time_prob(stop_id='8503308', transport_type='Zug', hour=9, time_tolerance=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798897178073305\n"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "print(get_on_time_prob(stop_id='8503308', transport_type='Zug', hour=7, time_tolerance=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Algorithm for route planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load the data that we store in loacal before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get run the algorithms on local for faster speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import copy\n",
    "from hdfs3 import HDFileSystem\n",
    "username = 'dwu'\n",
    "hdfs = HDFileSystem(host='hdfs://iccluster040.iccluster.epfl.ch', port=8020, user='ebouille') # impersonate ebouille to read the file\n",
    "import pandas as pd\n",
    "files = hdfs.glob('/user/{0}/file/timetable/*.parquet'.format(username))\n",
    "timetable = pd.DataFrame()\n",
    "for file in files:\n",
    "    with hdfs.open(file) as f:\n",
    "        timetable = timetable.append(pd.read_parquet(f))\n",
    "        \n",
    "files = hdfs.glob('/user/{0}/file/stops_walk/*.parquet'.format(username))\n",
    "stops_walk = pd.DataFrame()\n",
    "for file in files:\n",
    "    with hdfs.open(file) as f:\n",
    "        stops_walk = stops_walk.append(pd.read_parquet(f))\n",
    "        \n",
    "        \n",
    "files = hdfs.glob('/user/{0}/file/stops_ids/*.parquet'.format(username))\n",
    "stops_ids = pd.DataFrame()\n",
    "for file in files:\n",
    "    with hdfs.open(file) as f:\n",
    "        stops_ids = stops_ids.append(pd.read_parquet(f))\n",
    "\n",
    "stops_ids = stops_ids['stop_id'].unique().tolist()\n",
    "\n",
    "files = hdfs.glob('/user/{0}/file/stops_filt/*.parquet'.format(username))\n",
    "stops_filt = pd.DataFrame()\n",
    "for file in files:\n",
    "    with hdfs.open(file) as f:\n",
    "        stops_filt = stops_filt.append(pd.read_parquet(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8503315:0:2'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "stops_filt.head(3)\n",
    "stops_ids[340]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Implement of the algorithm\n",
    "We implement 2 algorithm:\n",
    "1. The RAPTOR algorithm from this paper:https://www.microsoft.com/en-us/research/wp-content/uploads/2012/01/raptor_alenex.pdf \n",
    "2. A modified version of RAPTOR algorithm, so that it can find the optimal path with the success probability larger than Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import numpy as np\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "walking_table = stops_walk[['stop_id','stop_id2','walk_time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The original implementation of the RAPTOR algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of the algorithm is board first search and target pruning. \n",
    "\n",
    "The algorithm is shown as follows:\n",
    "- Input: `source_stop`, `destination_stop`, `begin_time`, `time_limit`, `max_trans`\n",
    "- Output: the optimal route in  `time_limit`, and with at most `max_trans` transfers (walk path also consider as a trasfer)\n",
    "- 1. Intialize the a `result_time_table[p][i]`, which represent the optimal arrival time at stop `p` with at most `i` tranfers, we set `result_time_table[source_stop][0]= begin_time`, and mark `source_stop`\n",
    "- 2. At each round `i`, for all marked stops `p`, we find all trips that is valid w.r.t `result_time_table[p][i]`, that is a trip whose `depature_time > result_time_table[p][i]`\n",
    "- 3. For each trip `t` we found above, we traverse all the subsequent stops `p_t` in this trip, and if it is a better trip for `p_t`(that is `result_time_table[p_t][i] > arrival_time[p_t]`), we mark `p_t`.\n",
    "- 4. We run until there are no stops that is marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def find_walking(stop_id, time):\n",
    "    walking_next_stop_list = walking_table[walking_table['stop_id']== stop_id][['stop_id2']].values.tolist()\n",
    "    walking_next_time_list = (walking_table[walking_table['stop_id']== stop_id][['walk_time']].values + time).tolist()\n",
    "    return walking_next_stop_list, walking_next_time_list\n",
    "    \n",
    "    \n",
    "def find_trip(stop_id, time, time_table):\n",
    "    return time_table[np.logical_and(time_table['stop_id']== stop_id, \\\n",
    "                                     time_table['departure_time']>= time)][[\"trip_id\"]].values.tolist()\n",
    "\n",
    "\n",
    "def getBestRoutes(source_stop, destination_stop, begin_time, time_limit, max_trans):\n",
    "    time_table = timetable[np.logical_and(timetable['departure_time']>= begin_time, timetable['arrival_time']<= (begin_time + time_limit))]\n",
    "    \n",
    "    result_time_table = np.zeros([len(stops_ids), max_trans], dtype = int, order = 'C')\n",
    "    result_time_table = result_time_table - 1\n",
    "    result_path_table = np.zeros([len(stops_ids), max_trans], dtype = int, order = 'C')\n",
    "    result_path_table = result_time_table - 1\n",
    "    source_stop_index = stops_ids.index(source_stop)\n",
    "    result_time_table[source_stop_index] = begin_time\n",
    "    result_path_table[source_stop_index] = -2\n",
    "    \n",
    "    result_trip_info_table = np.zeros([len(stops_ids), max_trans], dtype = int, order = 'C')\n",
    "    result_trip_info_table = result_trip_info_table - 1\n",
    "    \n",
    "    trips_list = timetable[['trip_id']].drop_duplicates().values.tolist()\n",
    "    trips_list = [r[0] for r in trips_list]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    stop_list_next_iter = []\n",
    "    stop_list_next_iter.append(source_stop)\n",
    "    stop_list = []\n",
    "    time_list_next_iter = []\n",
    "    time_list_next_iter.append(begin_time)\n",
    "    time_list = []\n",
    "    \n",
    "    \n",
    "    for i in range(max_trans):\n",
    "        for j in range(len(stop_list_next_iter)):\n",
    "        \n",
    "            now_index = stops_ids.index(stop_list_next_iter[j])\n",
    "            stop_result, time_result= find_walking(stop_list_next_iter[j], time_list_next_iter[j])\n",
    "            \n",
    "            # find all walk path\n",
    "            for k in range(len(stop_result)):\n",
    "                stop_index = stops_ids.index(stop_result[k][0])\n",
    "                if result_time_table[stop_index][0] == -1:\n",
    "                    result_time_table[stop_index] = time_result[k][0]\n",
    "                    result_path_table[stop_index] = now_index\n",
    "                    result_trip_info_table[stop_index] = -100\n",
    "                    stop_list.append(stop_result[k][0])\n",
    "                elif result_time_table[stop_index][i] > time_result[k][0]:\n",
    "                    for l in range(max_trans - i):\n",
    "                        result_time_table[stop_index][i+l] = time_result[k][0]\n",
    "                        result_path_table[stop_index][i+l] = now_index\n",
    "                        result_trip_info_table[stop_index][i+l] = -100 #represent walk\n",
    "                        \n",
    "                    stop_list.append(stop_result[k][0])\n",
    "                    \n",
    "            # find all valid trips        \n",
    "            trip_result = find_trip(stop_list_next_iter[j], time_list_next_iter[j], time_table) \n",
    "            \n",
    "            for s in range(len(trip_result)):\n",
    "                    \n",
    "                trip_time_table = time_table[time_table['trip_id']== trip_result[s][0]]\n",
    "                stop_arrival_time = trip_time_table[trip_time_table['stop_id']== stop_list_next_iter[j]][[\"arrival_time\"]].values.tolist()[0][0]\n",
    "                stop_result = trip_time_table[trip_time_table['arrival_time']> stop_arrival_time][[\"stop_id\"]].values.tolist()\n",
    "                time_result = trip_time_table[trip_time_table['arrival_time']> stop_arrival_time][[\"arrival_time\"]].values.tolist()\n",
    "                \n",
    "                \n",
    "                \n",
    "                for k in range(len(stop_result)):\n",
    "                    stop_index = stops_ids.index(stop_result[k][0])\n",
    "                    if result_time_table[stop_index][0] == -1:\n",
    "                        result_time_table[stop_index] = time_result[k][0]\n",
    "                        result_path_table[stop_index] = now_index\n",
    "                        result_trip_info_table[stop_index] = trips_list.index(trip_result[s][0])\n",
    "                        stop_list.append(stop_result[k][0])\n",
    "                    elif result_time_table[stop_index][i] > time_result[k][0]:\n",
    "                        for l in range(max_trans - i):\n",
    "                            result_time_table[stop_index][i+l] = time_result[k][0]\n",
    "                            result_path_table[stop_index][i+l] = now_index \n",
    "                            #result_path_table[stop_index] = now_index \n",
    "                            result_trip_info_table[stop_index][i+l] = trips_list.index(trip_result[s][0])\n",
    "                        stop_list.append(stop_result[k][0])\n",
    "        stop_list_next_iter = list(set(stop_list))\n",
    "        stop_list = []\n",
    "        for j in range(len(stop_list_next_iter)):\n",
    "            stop_index = stops_ids.index(stop_list_next_iter[j])\n",
    "            time_list.append(result_time_table[stop_index][i])\n",
    "        time_list_next_iter = time_list\n",
    "        time_list = []\n",
    "    \n",
    "    final_result = []\n",
    "    final_time = []\n",
    "    final_trips = []\n",
    "    now_index = stops_ids.index(destination_stop)\n",
    "    i = max_trans - 1\n",
    "    #while(True):\n",
    "    while(True):\n",
    "        final_result.append(now_index)\n",
    "        final_time.append(result_time_table[now_index][i])\n",
    "        if (result_time_table[now_index][i] == -1) and (now_index != stops_ids.index(source_stop)):\n",
    "            print('no path is found')\n",
    "            break;\n",
    "            \n",
    "        trip_index =  result_trip_info_table[now_index][i]\n",
    "        if trip_index == -100:\n",
    "            final_trips.append('walk')\n",
    "        elif trip_index>-1:\n",
    "            final_trips.append(trips_list[trip_index])\n",
    "        else:\n",
    "            final_trips.append(trip_index)\n",
    "        now_index = result_path_table[now_index][i]\n",
    "        i = i - 1\n",
    "        if now_index == -2:\n",
    "            break\n",
    "    \n",
    "    return final_result, final_time, final_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified version of RAPTOR Algorithm\n",
    "\n",
    "Idea: The RAPTOR Algorithm is based on board first search, this is not suitable to for calculate the success probability, because in board first search, one can not see a complete route; however we can get a complete route at each round for deep first search. So in this algorithm, we change the board first search to deep first search, and the rest is same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def getBestRoutes_DFS(source_stop, destination_stop, begin_time, time_limit, max_trans, min_prob):\n",
    "    time_table = timetable[np.logical_and(timetable['departure_time']>= begin_time, timetable['arrival_time']<= (begin_time + time_limit))]\n",
    "    \n",
    "    result_time_table = np.zeros([len(stops_ids), max_trans], dtype = int, order = 'C')\n",
    "    result_time_table = result_time_table - 1\n",
    "    result_path_table = np.zeros([len(stops_ids), max_trans], dtype = int, order = 'C')\n",
    "    result_path_table = result_time_table - 1\n",
    "    source_stop_index = stops_ids.index(source_stop)\n",
    "    result_time_table[source_stop_index] = begin_time\n",
    "    result_path_table[source_stop_index] = -2\n",
    "    \n",
    "    result_prob_table = np.zeros([len(stops_ids), max_trans], dtype = int, order = 'C')\n",
    "    result_prob_table = result_time_table - 1\n",
    "    \n",
    "    result_trip_info_table = np.zeros([len(stops_ids), max_trans], dtype = int, order = 'C')\n",
    "    result_trip_info_table = result_trip_info_table - 1\n",
    "    \n",
    "    trips_list = timetable[['trip_id']].drop_duplicates().values.tolist()\n",
    "    trips_list = [r[0] for r in trips_list]\n",
    "    \n",
    "    #min_prob = min_prob**(1/float(max_trans))\n",
    "    #result_trip_info_table[now_index][i]\n",
    "    \n",
    "\n",
    "    #stop_list_next_iter = []\n",
    "    #stop_list_next_iter.append((source_stop,0))\n",
    "    \n",
    "    stop_list = []\n",
    "    stop_list.append((source_stop,0))\n",
    "    #time_list_next_iter = []\n",
    "    #time_list_next_iter.append(begin_time)\n",
    "    time_list = []\n",
    "    time_list.append((begin_time))\n",
    "    \n",
    "    \n",
    "    while len(stop_list) > 0:\n",
    "        \n",
    "        s = stop_list.pop()\n",
    "        curr_stop_id = s[0]\n",
    "        curr_count = s[1]\n",
    "        curr_arr_time  = time_list.pop()\n",
    "        \n",
    "        #print(s)\n",
    "    \n",
    "        if curr_count < max_trans:\n",
    "            \n",
    "            i = curr_count\n",
    "            if curr_stop_id == source_stop and curr_count == 0:\n",
    "                trans_count = 0\n",
    "            else:\n",
    "                trans_count = i+1\n",
    "            \n",
    "            now_index = stops_ids.index(curr_stop_id)\n",
    "            stop_result, time_result= find_walking(curr_stop_id, curr_arr_time)\n",
    "            \n",
    "            # find all walk path\n",
    "            for k in range(len(stop_result)):\n",
    "                stop_index = stops_ids.index(stop_result[k][0])\n",
    "                if result_time_table[stop_index][0] == -1:\n",
    "                    result_time_table[stop_index] = time_result[k][0]\n",
    "                    result_path_table[stop_index] = now_index\n",
    "                    result_trip_info_table[stop_index] = -100\n",
    "                    result_prob_table[stop_index] = 1\n",
    "                    if (stop_result[k][0],i+1) not in stop_list:\n",
    "                                stop_list.append((stop_result[k][0],trans_count))\n",
    "                                time_list.append(time_result[k][0])\n",
    "                elif result_time_table[stop_index][i] > time_result[k][0]:\n",
    "                    for l in range(max_trans - i):\n",
    "                        result_time_table[stop_index][i+l] = time_result[k][0]\n",
    "                        result_path_table[stop_index][i+l] = now_index\n",
    "                        result_trip_info_table[stop_index][i+l] = -100 #represent walk                       \n",
    "                    if (stop_result[k][0],i+1) not in stop_list:\n",
    "                                stop_list.append((stop_result[k][0],trans_count))\n",
    "                                time_list.append(time_result[k][0])\n",
    "                    \n",
    "            # find all valid trips        \n",
    "            trip_result = find_trip(curr_stop_id, curr_arr_time, time_table) \n",
    "            \n",
    "            for s in range(len(trip_result)):\n",
    "\n",
    "                trip_time_table = time_table[time_table['trip_id']== trip_result[s][0]]\n",
    "                stop_arrival_time = trip_time_table[trip_time_table['stop_id']== curr_stop_id][[\"arrival_time\"]].values.tolist()[0][0]\n",
    "                stop_departure_time = trip_time_table[trip_time_table['stop_id']== curr_stop_id][[\"departure_time\"]].values.tolist()[0][0]\n",
    "                stop_result = trip_time_table[trip_time_table['arrival_time']> stop_arrival_time][[\"stop_id\"]].values.tolist()\n",
    "                time_result = trip_time_table[trip_time_table['arrival_time']> stop_arrival_time][[\"arrival_time\"]].values.tolist()\n",
    "                \n",
    "                if trip_result[s][0] is not result_trip_info_table[now_index][i]:\n",
    "                    # which means we have a transfer here\n",
    "                    trip_id = trip_result[s][0]\n",
    "                    transport_type = trip_time_table[trip_time_table['stop_id']== curr_stop_id][[\"route_desc\"]].values.tolist()[0][0]\n",
    "                    hour = int(stop_arrival_time/3600)\n",
    "                    time_tolerance = stop_departure_time - result_time_table[now_index][i]\n",
    "                    prob = get_on_time_prob(stop_id=curr_stop_id, transport_type=transport_type, hour=hour, time_tolerance=time_tolerance)\n",
    "                    if prob*result_prob_table[now_index][i] < min_prob:\n",
    "                        continue\n",
    "                    else:\n",
    "                        result_prob_table[now_index][i] = prob*result_prob_table[now_index][i]\n",
    "                \n",
    "                for k in range(len(stop_result)):\n",
    "                    \n",
    "                    stop_index = stops_ids.index(stop_result[k][0])\n",
    "                    if result_time_table[stop_index][0] == -1:\n",
    "                        result_time_table[stop_index] = time_result[k][0]\n",
    "                        result_path_table[stop_index] = now_index\n",
    "                        result_trip_info_table[stop_index] = trips_list.index(trip_result[s][0])\n",
    "                        result_prob_table[stop_index] = 1\n",
    "                        if (stop_result[k][0],i+1) not in stop_list:\n",
    "                            stop_list.append((stop_result[k][0],trans_count))\n",
    "                            time_list.append(time_result[k][0])\n",
    "                    elif result_time_table[stop_index][i] > time_result[k][0]:\n",
    "                        for l in range(max_trans - i):\n",
    "                            result_time_table[stop_index][i+l] = time_result[k][0]\n",
    "                            result_path_table[stop_index][i+l] = now_index \n",
    "                            #result_path_table[stop_index] = now_index \n",
    "                            result_trip_info_table[stop_index][i+l] = trips_list.index(trip_result[s][0])\n",
    "                            if (stop_result[k][0],i+1) not in stop_list:\n",
    "                                stop_list.append((stop_result[k][0],trans_count))\n",
    "                                time_list.append(time_result[k][0])\n",
    "        #stop_list_next_iter = list(set(stop_list))\n",
    "        #stop_list = []\n",
    "        #for j in range(len(stop_list_next_iter)):\n",
    "        #    stop_index = stops_ids.index(stop_list_next_iter[j])\n",
    "        #    time_list.append(result_time_table[stop_index][i])\n",
    "        #time_list_next_iter = time_list\n",
    "        #time_list = []\n",
    "    \n",
    "    final_result = []\n",
    "    final_time = []\n",
    "    final_trips = []\n",
    "    now_index = stops_ids.index(destination_stop)\n",
    "    i = max_trans - 1\n",
    "    #while(True):\n",
    "    while(True):\n",
    "        final_result.append(now_index)\n",
    "        final_time.append(result_time_table[now_index][i])\n",
    "        if (result_time_table[now_index][i] == -1) and (now_index != stops_ids.index(source_stop)):\n",
    "            print('no path is found')\n",
    "            break;\n",
    "            \n",
    "        trip_index =  result_trip_info_table[now_index][i]\n",
    "        if trip_index == -100:\n",
    "            final_trips.append('walk')\n",
    "        elif trip_index>-1:\n",
    "            final_trips.append(trips_list[trip_index])\n",
    "        else:\n",
    "            final_trips.append(trip_index)\n",
    "        now_index = result_path_table[now_index][i]\n",
    "        i = i - 1\n",
    "        if now_index == -2:\n",
    "            break\n",
    "    \n",
    "    return final_result, final_time, final_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some simple example for our algorithm, just to show that our algorithm works. A more conrete validation will be shown in next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([684, 1664, 1850, 1511],\n",
       " [41664, 41520, 39660, 36899],\n",
       " ['walk', '224.TA.26-303-j19-1.3.R', '221.TA.26-302-j19-1.5.H', -1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "final_result, final_time, final_trips= getBestRoutes('8590615','8590271', 36899, 7200, 3)\n",
    "final_result, final_time, final_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "final_result, final_time, final_trips= getBestRoutes('8590615','8590271', 36899, 7200, 3)\n",
    "final_result, final_time, final_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the low probability low, to make sure it works, A more concrete validation will be shown in next part\n",
    "\n",
    "Note: This algorithm may need to run for few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "final_result, final_time, final_trips = getBestRoutes_DFS('8590615','8590271', 36899, 7200, 3, 0.1)\n",
    "final_result, final_time, final_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to change the result in forms that could be used in later processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "def change_result_format(final_result,final_time,final_trips):\n",
    "    final_result = final_result[::-1]\n",
    "    final_time = final_time[::-1]\n",
    "    final_trips = final_trips[::-1]\n",
    "    \n",
    "    final_departure = []\n",
    "            \n",
    "        \n",
    "    \n",
    "    path_list = []\n",
    "    trip_list = []\n",
    "    time_list = []\n",
    "    \n",
    "    for i,stop_index in enumerate(final_result):\n",
    "        stop_id = stops_ids[stop_index]\n",
    "        if i == 0:\n",
    "            trip_id = final_trips[i+1]\n",
    "            path_list.append(stop_id)\n",
    "            trip_list.append(trip_id)\n",
    "            if trip_id is not 'walk':\n",
    "                \n",
    "                stop_dep_time = timetable[(timetable['stop_id']==stop_id)&\n",
    "                                        (timetable['trip_id']==trip_id)][[\"departure_time\"]].values.tolist()[0][0]\n",
    "                \n",
    "                time_list.append(stop_dep_time)\n",
    "                \n",
    "            else:\n",
    "                time_list.append( final_time[i])\n",
    "            \n",
    "        elif i == len(final_result)-1:\n",
    "            trip_id = final_trips[i]\n",
    "            path_list.append(stop_id)\n",
    "            time_list.append(final_time[i])\n",
    "            trip_list.append(trip_id)\n",
    "            \n",
    "        else:\n",
    "            trip_id = final_trips[i+1]\n",
    "            path_list.append(stop_id)\n",
    "            path_list.append(stop_id)\n",
    "            trip_list.append(trip_id)\n",
    "            trip_list.append(trip_id)\n",
    "            if trip_id is not 'walk':\n",
    "                #print((trip_id,stop_id))\n",
    "                stop_dep_time = timetable[(timetable['stop_id']==stop_id)&\n",
    "                                        (timetable['trip_id']==trip_id)][[\"departure_time\"]].values.tolist()[0][0]\n",
    "\n",
    "                time_list.append(final_time[i])\n",
    "                time_list.append(stop_dep_time)\n",
    "            else: \n",
    "                time_list.append(final_time[i])\n",
    "                time_list.append(final_time[i])\n",
    "                \n",
    "    trip_list = trip_list[:-1]\n",
    "    trip_list.insert(0,trip_list[0])\n",
    "        \n",
    "    return path_list, time_list,trip_list\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['8590615', '8590794', '8590794', '8591891', '8591891', '8590271'],\n",
       " [38460, 39660, 40200, 41520, 41520, 41664],\n",
       " ['221.TA.26-302-j19-1.5.H',\n",
       "  '221.TA.26-302-j19-1.5.H',\n",
       "  '224.TA.26-303-j19-1.3.R',\n",
       "  '224.TA.26-303-j19-1.3.R',\n",
       "  'walk',\n",
       "  'walk'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "path_list, time_list,trip_list = change_result_format(final_result, final_time, final_trips)\n",
    "path_list, time_list,trip_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Validation of Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Compare with Google Maps application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our vedio, we demonstrate an example, the upper picture is the one given by google maps application, and the lower one is our recommendation. It can be told that these two are quite similar.\n",
    "starting point: Geroldswil, Grindlen\n",
    "destination:Spreitenbach, Dorf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Compute the path completion probability of our recommendation\n",
    "First, we recomend a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "stop_id = ['8590615', '8590805', '8590805', '8591891', '8591891', '8590271']\n",
    "arrival_time = [38460, 39660, 40200, 41520, 41520, 41664]\n",
    "final_trip =  ['221.TA.26-302-j19-1.5.H',\n",
    "  '221.TA.26-302-j19-1.5.H',\n",
    "  '224.TA.26-303-j19-1.3.R',\n",
    "  '224.TA.26-303-j19-1.3.R',\n",
    "  'walk',\n",
    "  'walk']\n",
    "def path_todict(final_trips, stop_ids, arrival_times):\n",
    "    path_list = []\n",
    "    for trip_id, stop_id, arrival_time in zip(final_trips,stop_ids, arrival_times):\n",
    "        stop_dict ={}\n",
    "        stop_dict['trip_id'] = trip_id\n",
    "        stop_dict['stop_id'] = stop_id\n",
    "        stop_dict['arrival_time'] = arrival_time\n",
    "        path_list.append(stop_dict)\n",
    "    return path_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d6261d18d4c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msplitted_stop_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitted_time_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitted_id_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mstop_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrip_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_route\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-d6261d18d4c5>\u001b[0m in \u001b[0;36msplit_route\u001b[0;34m(route)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mid_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrip_id\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trip_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtrip_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trip_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mid_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0msplitted_stop_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "%%local\n",
    "def split_route(route):\n",
    "    '''\n",
    "    Split the recommended path into segments using the same transport type\n",
    "    '''\n",
    "    splitted_stop_list = []\n",
    "    splitted_time_list = []\n",
    "    splitted_id_list = []\n",
    "    segment = None\n",
    "    timeline = None\n",
    "    idline = None\n",
    "    for id_, stop in enumerate(route):\n",
    "        if id_ == 0 or trip_id != stop['trip_id']:\n",
    "            trip_id = stop['trip_id']\n",
    "            if id_ != 0:\n",
    "                splitted_stop_list.append(segment)\n",
    "                splitted_time_list.append(timeline)\n",
    "                splitted_id_list.append(idline)\n",
    "            segment = [stop['stop_id']]\n",
    "            timeline = [stop['arrival_time']]\n",
    "            idline = [stop['trip_id']]\n",
    "        else:\n",
    "            segment.append(stop['stop_id'])\n",
    "            timeline.append(stop['arrival_time'])\n",
    "            idline.append(stop['trip_id'])\n",
    "    splitted_stop_list.append(segment)\n",
    "    splitted_time_list.append(timeline)\n",
    "    splitted_id_list.append(idline)\n",
    "    \n",
    "            \n",
    "    return splitted_stop_list, splitted_time_list, splitted_id_list\n",
    "        \n",
    "stop_list, time_list, trip_list = split_route(path_list)\n",
    "print(stop_list)\n",
    "print(time_list)\n",
    "print(trip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "files = hdfs.glob('/user/{0}/file/delay_table/*.parquet'.format('dwu'))\n",
    "delay_table = pd.DataFrame()\n",
    "for file in files:\n",
    "    with hdfs.open(file) as f:\n",
    "        delay_table = delay_table.append(pd.read_parquet(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import numpy as np\n",
    "def get_on_time_prob(stop_id, transport_type, hour, time_tolerance):\n",
    "\n",
    "    delay_dist = np.array(delay_table[(delay_table['stop_id']==stop_id)&\n",
    "                                        (delay_table['transport_type']==transport_type.lower())&\n",
    "                                      (delay_table['hour']==hour)][[\"delay\",\"delay_count\"]])\n",
    "    if delay_dist.size==0:\n",
    "        return 0\n",
    "\n",
    "    success=0\n",
    "    for minute, count in delay_dist:\n",
    "        if minute<=time_tolerance:\n",
    "            success+=count\n",
    "    return float(success)/(delay_dist[:,1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, compute the probability with the record of SBB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local ## working here\n",
    "from math import floor\n",
    "def path_completion_prob(stop_list, time_list, trip_list, stops_walk, delay_table, timetable):\n",
    "\n",
    "    completion_prob = 1\n",
    "    for i, (stop_ids, arrival_times, trip_ids) in enumerate(zip(stop_list, time_list, trip_list)):\n",
    "        print(\"=========\")\n",
    "        if (i<= len(stop_list) - 2) and (trip_ids[-1] != trip_list[i+1][0]):\n",
    "            walk_start_pt = stop_ids[-1]\n",
    "            walk_end_pt = stop_list[i+1][0]\n",
    "            condition1 = (stops_walk[\"stop_id2\"] == walk_start_pt)\n",
    "            condition2 = (stops_walk[\"stop_id\"] ==walk_end_pt)\n",
    "            condition = condition1&condition2\n",
    "            sub_df = stops_walk[condition]\n",
    "\n",
    "            try:\n",
    "                if walk_start_pt == walk_end_pt:\n",
    "                    walk_time = 120\n",
    "                else:\n",
    "                    walk_time = sub_df.iat[0,-1]\n",
    "    #                 print(walk_time)\n",
    "\n",
    "                tolerance_time = time_list[i+1][0] - arrival_times[-1] - walk_time\n",
    "    #                 print(time_list[i+1][0])\n",
    "    #                 print(arrival_times[-1])\n",
    "    #                 print(tolerance_time)\n",
    "                if trip_ids[-1] == 'walk':\n",
    "                    transit_on_time_prob = 1 if tolerance_time >0 else 0\n",
    "                else:\n",
    "                    condition3 = timetable[\"stop_id\"] == stop_ids[-1]\n",
    "                    condition4 = timetable[\"trip_id\"] == trip_ids[-1]\n",
    "                    condition_ = condition3 & condition4\n",
    "                    transport_type_sub_df = timetable[condition_]\n",
    "        #                 return transport_type_sub_df\n",
    "                    transport_type = transport_type_sub_df.iloc[0].at['route_desc']\n",
    "        #                 print('transport_type {}'.format(transport_type))\n",
    "\n",
    "        #                 print('made to here')\n",
    "        #                 print(transport_type)\n",
    "                    hour = floor(arrival_times[-1]/3600)\n",
    "                    if trip_list[i+1][0] == 'walk':\n",
    "                        transit_on_time_prob = 1\n",
    "\n",
    "                    else:\n",
    "                        transit_on_time_prob = get_on_time_prob(stop_ids[-1], transport_type, hour, tolerance_time)\n",
    "        #                     print(stop_ids[-1])\n",
    "    #                     print(transport_type)\n",
    "    #                     print(hour)\n",
    "    #                     print(\"probability: {}\".format(transit_on_time_prob))\n",
    "                print(\"probability of completing the No{}. transition: {}\".format(i+1,transit_on_time_prob))\n",
    "                completion_prob*=transit_on_time_prob\n",
    "\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print('walking is not an option between {} and {}'.format(walk_start_pt, walk_end_pt))\n",
    "                return\n",
    "    print(\"SUMMARY  The probability of completing the entire path is: {}\".format(completion_prob))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "## Find a bad stop, which may have large delay\n",
    "hour = 10\n",
    "time_tolerance = 5\n",
    "min_prob = 1\n",
    "min_stop =''\n",
    "min_transport_type = ''\n",
    "for stop in stops_ids[1601:1910]:\n",
    "    \n",
    "    transport_type_list = timetable[timetable['stop_id']== stop][[\"route_desc\"]].values.tolist()\n",
    "    if len(transport_type_list)>0:\n",
    "        transport_type = transport_type_list[0][0]\n",
    "    prob = get_on_time_prob(stop_id=stop, transport_type=transport_type, hour=hour, time_tolerance=time_tolerance)\n",
    "    if (prob<min_prob) and prob>0:\n",
    "        min_prob = prob\n",
    "        min_stop = stop\n",
    "        min_transport_type = transport_type\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('8591428', 0.8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "min_stop, min_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3, 271, 142, 1438, 222],\n",
       " [41340, 40404, 40380, 37620, 36899],\n",
       " ['213.TA.26-704-j19-1.7.R',\n",
       "  'walk',\n",
       "  '99.TA.26-725-j19-1.5.H',\n",
       "  '54.TA.26-813-j19-1.2.R',\n",
       "  -1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "# Here is the algorithm that we do not consider the \n",
    "final_result, final_time, final_trips= getBestRoutes('8581546',stops_ids[3], 36899, 7200, 4)\n",
    "final_result, final_time, final_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('8590610', '8576127:0:B', '8576127:0:A', '8573504', '8581546')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%local\n",
    "stops_ids[3], stops_ids[271],stops_ids[142],stops_ids[1438],stops_ids[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "path_list, time_list,trip_list = change_result_format(final_result, final_time, final_trips)\n",
    "path_dict = path_todict(trip_list, path_list, time_list)\n",
    "stop_list, time_list, trip_list = split_route(path_dict)\n",
    "print(stop_list, time_list, trip_list)\n",
    "probability = path_completion_prob(stop_list, time_list, trip_list, stops_walk, delay_table, timetable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, the path we recommended from 8581546 to 8590610 has a completion probability of 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Verify that our designed route appears in the data pool, justifying its feasibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "for i,(stop_segment, timeline, idline) in enumerate(zip(stop_list, time_list, trip_list)): #to be modified\n",
    "    for j,(stop, time, trip) in enumerate(zip(stop_segment, timeline, idline)):\n",
    "        condition1 = timetable[\"stop_id\"] == stop\n",
    "        condition2 = timetable[\"arrival_time\"] == time\n",
    "        condition3 = timetable[\"trip_id\"] == trip\n",
    "        condition = condition1&condition2&condition3\n",
    "        same_as_recommendation = timetable[condition]\n",
    "        if same_as_recommendation.stop_id.count()!=0:\n",
    "            print(\"The No.{} stop of No.{} trip in our recommendation is scheduled\".format(j+1,i+1))\n",
    "        elif trip == 'walk':\n",
    "            print(\"This part is done by walking\")\n",
    "        else:\n",
    "            print(\"The No.{} stop of No.{} trip in our recommendation is scheduled\".format(j+1,i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, beside one trip that is done by walking, all the other trips are scheduled by SBB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we implement an user interface. In the User interface, we use the algorithm without input the minimum probability that is the original RATPOR algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "Label_1 = widgets.Label(\"Source stop\")\n",
    "display(Label_1)\n",
    "Text_1 = widgets.Text()\n",
    "display(Text_1)\n",
    "Label_2 = widgets.Label(\"Destination stop\")\n",
    "display(Label_2)\n",
    "Text_2 = widgets.Text()\n",
    "display(Text_2)\n",
    "Label_3 = widgets.Label(\"Start Time\")\n",
    "display(Label_3)\n",
    "Text_3 = widgets.Text()\n",
    "display(Text_3)\n",
    "Label_4 = widgets.Label(\"Max time limit\")\n",
    "display(Label_4)\n",
    "Text_4 = widgets.Text()\n",
    "display(Text_4)\n",
    "Label_5 = widgets.Label(\"Max transfers\")\n",
    "display(Label_5)\n",
    "Text_5 = widgets.Text()\n",
    "display(Text_5)\n",
    "Button = widgets.Button(description = \"Start\")\n",
    "display(Button)\n",
    "\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "def run(b):\n",
    "    QD = Text_1.value\n",
    "    ZD = Text_2.value\n",
    "    CFSJ = int(Text_3.value)\n",
    "    ZDSJ = int(Text_4.value)\n",
    "    ZDHCCS = int(Text_5.value)\n",
    "    with output:\n",
    "        final_result, final_time, final_trips = getBestRoutes(QD, ZD, CFSJ, ZDSJ, ZDHCCS)\n",
    "        print(final_result, final_time, final_trips)\n",
    "        m = folium.Map(location=[47.3842, 8.53185], zoom_start=11)\n",
    "        long = stops_filt[stops_filt['stop_id']== stops_ids[final_result[0]]][['stop_lon']].values.tolist()[0][0]\n",
    "        lat = stops_filt[stops_filt['stop_id']== stops_ids[final_result[0]]][['stop_lat']].values.tolist()[0][0]\n",
    "        folium.Marker(location=[lat, long],popup=stops_ids[final_result[0]], tooltip=final_time[0],icon=folium.Icon(color=\"blue\", icon=\"info-sign\"),).add_to(m)\n",
    "        \n",
    "        #print(final_result, final_time, final_trips)\n",
    "        \n",
    "        for i in range(len(final_result)-1):\n",
    "            timetable_next = stops_filt[stops_filt['stop_id']== stops_ids[final_result[i]]]\n",
    "            timetable_this = stops_filt[stops_filt['stop_id']== stops_ids[final_result[i+1]]]\n",
    "            \n",
    "            \n",
    "            long_1 = timetable_next[['stop_lon']]\\\n",
    "            .values.tolist()[0][0]\n",
    "            lat_1 = timetable_next[['stop_lat']]\\\n",
    "            .values.tolist()[0][0]\n",
    "            long_2 = timetable_this[['stop_lon']]\\\n",
    "            .values.tolist()[0][0]\n",
    "            lat_2 = timetable_this[['stop_lat']]\\\n",
    "            .values.tolist()[0][0]\n",
    "            \n",
    "            arrival_time_next = final_time[i]\n",
    "            arrival_time_this = final_time[i+1]\n",
    "            \n",
    "            trip_id = final_trips[i]\n",
    "            print(trip_id)\n",
    "#             trip_info = {}\n",
    "#             if trip_id == 'walk':\n",
    "#                 trip_info = {\n",
    "#                     'trip_id':'walk',\n",
    "#                     'route_desc':'walk',\n",
    "#                     'departure_time' :  arrival_time_this,\n",
    "#                     'arrival_time': arrival_time_next\n",
    "#                 }\n",
    "#             else:\n",
    "                #arrival_time =  timetable_next[timetable_next['trip_id']== trip_id][['arrival_time']]\\\n",
    "            #.values.tolist()[0][0]\n",
    "#                 departure_time_this = timetable_this[timetable_this['trip_id']== trip_id][['departure_time']]\\\n",
    "#             .values.tolist()[0][0]\n",
    "#                 departure_time_next = timetable_next[timetable_next['trip_id']== trip_id][['departure_time']]\\\n",
    "#             .values.tolist()[0][0]\n",
    "#                 route_desc = timetable[timetable['trip_id']== trip_id][['route_desc']]\\\n",
    "#             .values.tolist()[0][0]\n",
    "                \n",
    "#             trip_info = {\n",
    "#                     'trip_id':trip_id,\n",
    "#                     'route_desc': route_desc,\n",
    "#                     'departure_time' :  departure_time_this,\n",
    "#                     'arrival_time': arrival_time_next}\n",
    "            if i == len(final_result)-2:\n",
    "                folium.Marker(location=[lat_2, long_2],popup=stops_ids[final_result[i+1]],\\\n",
    "                          tooltip=final_time[i+1],icon=folium.Icon(color=\"green\", icon=\"info-sign\"),).add_to(m)\n",
    "            else:\n",
    "                folium.Marker(location=[lat_2, long_2],popup=stops_ids[final_result[i+1]],\\\n",
    "                          tooltip=final_time[i+1],icon=folium.Icon(color=\"red\", icon=\"info-sign\"),).add_to(m)\n",
    "#             folium.PolyLine(locations=[(lat_1, long_1),(lat_2, long_2)],popup=trip_info,\\\n",
    "#                             tooltip=trip_info, weight=2,color = 'blue').add_to(m)\n",
    "            folium.PolyLine(locations=[(lat_1, long_1),(lat_2, long_2)], weight=2,color = 'blue').add_to(m)\n",
    "            \n",
    "        display(m)  \n",
    "Button.on_click(run)\n",
    "\n",
    "\n",
    "# 8573711\n",
    "# 8590610\n",
    "# 34000\n",
    "# 3600\n",
    "# 4\n",
    "# \n",
    "# 8590615\n",
    "# 8590619\n",
    "# 36899\n",
    "# 7200\n",
    "# 3\n",
    "# \n",
    "# 8590615\n",
    "# 8590619\n",
    "# 27000\n",
    "# 7200\n",
    "# 4\n",
    "#\n",
    "#8590887\n",
    "#8587020\n",
    "#36899\n",
    "#7200\n",
    "#4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we implement an user interface. In this User interface, we use the algorithm with input the minimum probability that is our modified RATPOR algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "Label_1 = widgets.Label(\"Source stop\")\n",
    "display(Label_1)\n",
    "Text_1 = widgets.Text()\n",
    "display(Text_1)\n",
    "Label_2 = widgets.Label(\"Destination stop\")\n",
    "display(Label_2)\n",
    "Text_2 = widgets.Text()\n",
    "display(Text_2)\n",
    "Label_3 = widgets.Label(\"Start Time\")\n",
    "display(Label_3)\n",
    "Text_3 = widgets.Text()\n",
    "display(Text_3)\n",
    "Label_4 = widgets.Label(\"Max time limit\")\n",
    "display(Label_4)\n",
    "Text_4 = widgets.Text()\n",
    "display(Text_4)\n",
    "Label_5 = widgets.Label(\"Max transfers\")\n",
    "display(Label_5)\n",
    "Text_5 = widgets.Text()\n",
    "display(Text_5)\n",
    "Label_6 = widgets.Label(\"Min probability\")\n",
    "display(Label_6)\n",
    "Text_6 = widgets.Text()\n",
    "display(Text_6)\n",
    "Button = widgets.Button(description = \"Start\")\n",
    "display(Button)\n",
    "\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "def run(b):\n",
    "    QD = Text_1.value\n",
    "    ZD = Text_2.value\n",
    "    CFSJ = int(Text_3.value)\n",
    "    ZDSJ = int(Text_4.value)\n",
    "    ZDHCCS = int(Text_5.value)\n",
    "    min_prob = int(Text_6.value)\n",
    "    with output:\n",
    "        final_result, final_time, final_trips = getBestRoutes_DFS(QD, ZD, CFSJ, ZDSJ, ZDHCCS,min_prob)\n",
    "        print(final_result, final_time, final_trips)\n",
    "        m = folium.Map(location=[47.3842, 8.53185], zoom_start=11)\n",
    "        long = stops_filt[stops_filt['stop_id']== stops_ids[final_result[0]]][['stop_lon']].values.tolist()[0][0]\n",
    "        lat = stops_filt[stops_filt['stop_id']== stops_ids[final_result[0]]][['stop_lat']].values.tolist()[0][0]\n",
    "        folium.Marker(location=[lat, long],popup=stops_ids[final_result[0]], tooltip=final_time[0],icon=folium.Icon(color=\"blue\", icon=\"info-sign\"),).add_to(m)\n",
    "        \n",
    "        #print(final_result, final_time, final_trips)\n",
    "        \n",
    "        for i in range(len(final_result)-1):\n",
    "            timetable_next = stops_filt[stops_filt['stop_id']== stops_ids[final_result[i]]]\n",
    "            timetable_this = stops_filt[stops_filt['stop_id']== stops_ids[final_result[i+1]]]\n",
    "            \n",
    "            \n",
    "            long_1 = timetable_next[['stop_lon']]\\\n",
    "            .values.tolist()[0][0]\n",
    "            lat_1 = timetable_next[['stop_lat']]\\\n",
    "            .values.tolist()[0][0]\n",
    "            long_2 = timetable_this[['stop_lon']]\\\n",
    "            .values.tolist()[0][0]\n",
    "            lat_2 = timetable_this[['stop_lat']]\\\n",
    "            .values.tolist()[0][0]\n",
    "            \n",
    "            arrival_time_next = final_time[i]\n",
    "            arrival_time_this = final_time[i+1]\n",
    "            \n",
    "            trip_id = final_trips[i]\n",
    "            print(trip_id)\n",
    "#             trip_info = {}\n",
    "#             if trip_id == 'walk':\n",
    "#                 trip_info = {\n",
    "#                     'trip_id':'walk',\n",
    "#                     'route_desc':'walk',\n",
    "#                     'departure_time' :  arrival_time_this,\n",
    "#                     'arrival_time': arrival_time_next\n",
    "#                 }\n",
    "#             else:\n",
    "                #arrival_time =  timetable_next[timetable_next['trip_id']== trip_id][['arrival_time']]\\\n",
    "            #.values.tolist()[0][0]\n",
    "#                 departure_time_this = timetable_this[timetable_this['trip_id']== trip_id][['departure_time']]\\\n",
    "#             .values.tolist()[0][0]\n",
    "#                 departure_time_next = timetable_next[timetable_next['trip_id']== trip_id][['departure_time']]\\\n",
    "#             .values.tolist()[0][0]\n",
    "#                 route_desc = timetable[timetable['trip_id']== trip_id][['route_desc']]\\\n",
    "#             .values.tolist()[0][0]\n",
    "                \n",
    "#             trip_info = {\n",
    "#                     'trip_id':trip_id,\n",
    "#                     'route_desc': route_desc,\n",
    "#                     'departure_time' :  departure_time_this,\n",
    "#                     'arrival_time': arrival_time_next}\n",
    "            if i == len(final_result)-2:\n",
    "                folium.Marker(location=[lat_2, long_2],popup=stops_ids[final_result[i+1]],\\\n",
    "                          tooltip=final_time[i+1],icon=folium.Icon(color=\"green\", icon=\"info-sign\"),).add_to(m)\n",
    "            else:\n",
    "                folium.Marker(location=[lat_2, long_2],popup=stops_ids[final_result[i+1]],\\\n",
    "                          tooltip=final_time[i+1],icon=folium.Icon(color=\"red\", icon=\"info-sign\"),).add_to(m)\n",
    "#             folium.PolyLine(locations=[(lat_1, long_1),(lat_2, long_2)],popup=trip_info,\\\n",
    "#                             tooltip=trip_info, weight=2,color = 'blue').add_to(m)\n",
    "            folium.PolyLine(locations=[(lat_1, long_1),(lat_2, long_2)], weight=2,color = 'blue').add_to(m)\n",
    "            \n",
    "        display(m)  \n",
    "Button.on_click(run)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "\n",
    "### Advantages:\n",
    "1. In our route planing algorithm, we do not need to construct a graph in implementation. Comapre to other graph structure based algorithms(for example Dijkstra, or weighted A*), our algorithmis more efficient compare to theirs. And as shown in the validation procedure, our route planing algorithm get a correct path.\n",
    "2. Embed the calculation of destination reaching probability into the RAPTOR algorithm. The original RAPTOR algorithm do not contain the calculation of destination reaching probability, because the original RAPTOR algorithm is board first search based, in each round , it do not construct a complete path. However, our's modified version is based deep first search, in which the algorithm construct a complete path in each round ,thus we could compute the success probability of a path in each round, and throw away the invalid one.\n",
    "3. Estimatioin of delay is unbiased since we use the frequence to estimate the delay probability.\n",
    "\n",
    "### Shortcomings and possible improvements:\n",
    "1. Our procedure of estimating the delay probability is not so efficient, since whenever we need to calculate the delay probability, we need to query the delay table and compute the frequence. An alternative approach is to  model the delay's distributions  at each stops, instead of just counting the frequence, which can increase running speed.\n",
    "2. More effort can be put on UI design. The route given in the map picture is simplified as straight lines in our version. An alternative approach is that we could show each stops through each trips, which looks better. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of work:\n",
    "- Xiaoqi Ma and Xiaoyu Lin mainly works on  the data preparation and build the predictive model. \n",
    "- Zhenyu Zhu and Diyuan Wu mainly works on the route planing algorithm, and Zhenyu Zhu also works on the user interface \n",
    "- Zhengqing Wu mainly works on the validation\n",
    "- All members in our team discuss for the framework of this project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
